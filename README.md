# NOAH_Sim

requirements
`chmod +x install_packages.sh`
`bash -x ./install_packages.sh`

名为"Noah"的系统架构，它包括容器、限制器、监视器等组件，并通过基于深度强化学习（DRL）的决策制定器来处理请求。要模拟这样的结构，你可以考虑以下步骤：

1. 定义组件和数据流：
容器（Container）：可以是一个环境或者框架，用来封装其它所有组件。
限制器（Limiter）：用来限制处理的请求数量或者速度。
监视器（Monitor）：用来收集运行时数据，如请求处理速度、错误率等。
数据收集（Collect）：负责从限制器和监视器收集数据。
阈值确定（Threshold determination）：基于收集到的数据，动态确定阈值。
基于DRL的决策制定器（DRL-based Decision Maker）：使用深度强化学习来优化决策过程，改进系统性能。
2. 选择技术栈：
可以使用Python语言，结合Flask或FastAPI框架来搭建服务端逻辑。
对于深度强化学习部分，可以考虑使用TensorFlow或PyTorch框架。
3. 实现逻辑：
开发API接口来接收和处理外部请求。
实现限制器逻辑，确保系统不会因请求过多而超负荷。
开发监视器组件，定期检查和记录系统性能指标。
设计数据收集机制，将监视器和限制器的数据整合起来。
实现一个基于深度强化学习的模型，根据实时数据调整系统阈值。
4. 测试与优化：
通过模拟不同的请求场景来测试系统的响应和稳定性。
根据测试结果调整DRL模型，优化系统性能。
5. 部署和监控：
将系统部署到服务器或云平台。
持续监控系统运行状态，必要时调整配置和模型。


main.py：主程序入口，用于启动服务和初始化所有组件。
config.py：存储配置信息，比如监视器的采样频率，限制器的请求阈值等。
api.py：定义API接口，处理外部请求。
limiter.py：实现限制器逻辑，控制请求流量。
monitor.py：实现监视器逻辑，监控系统运行状况。
collector.py：收集和汇总数据。
decision_maker.py：实现基于DRL的决策制定器。
drl_model.py：定义深度强化学习模型。


三个可运行文件：

main.py：启动服务器

train.py:训练模型

train_example.py：模拟发送多个请求

